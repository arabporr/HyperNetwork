{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "949a8d5f42b54bd8b49e9b0059924810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7eabf29f1e742088d68a4f6c91a77c6",
              "IPY_MODEL_25335ed8dd054ea3877dc546dddabdf5",
              "IPY_MODEL_1c9d30afd93e42e2be5c4d4213c0b21d"
            ],
            "layout": "IPY_MODEL_c3411d615d2347bd90f1b42bf160bac6"
          }
        },
        "f7eabf29f1e742088d68a4f6c91a77c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a7b768d7de42fcb1be543e37771521",
            "placeholder": "​",
            "style": "IPY_MODEL_e79bf3afffc84f6199990c6e9334fed8",
            "value": "100%"
          }
        },
        "25335ed8dd054ea3877dc546dddabdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a835b8a5614c6ba8206c217235b83b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82db98c3ff964f0eab8b452df1bd9436",
            "value": 100
          }
        },
        "1c9d30afd93e42e2be5c4d4213c0b21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c64ba16c4b04779b66c6797789d03e0",
            "placeholder": "​",
            "style": "IPY_MODEL_1ddccb91469c49518fe9f84802cf6f88",
            "value": " 100/100 [00:23&lt;00:00,  4.23it/s]"
          }
        },
        "c3411d615d2347bd90f1b42bf160bac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a7b768d7de42fcb1be543e37771521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79bf3afffc84f6199990c6e9334fed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a835b8a5614c6ba8206c217235b83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82db98c3ff964f0eab8b452df1bd9436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c64ba16c4b04779b66c6797789d03e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddccb91469c49518fe9f84802cf6f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHY1zCXXaQsU"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvLPRG7MHkfO"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.linalg import fractional_matrix_power as frac_mat_pow\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xWulQ-GIYW0",
        "outputId": "4970423d-562f-45ff-e137-a3ca9125f790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): # GPU operation have separate seed\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Fetching the device that will be used throughout this notebook\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "4gqO6uUXk8Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "oaAhGZfimsxn",
        "outputId": "101ef43d-d8dd-4ae6-ea00-f5ee39807777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0589c42e-136e-4726-b46f-38601f7b539d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0589c42e-136e-4726-b46f-38601f7b539d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vars.pt to vars.pt\n",
            "Saving Z_N.pt to Z_N.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars = torch.load('vars.pt')\n",
        "N, T, d = vars\n",
        "Z_N = torch.load('Z_N.pt')"
      ],
      "metadata": {
        "id": "4dO3j0Bfk_He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmRMVvALnS9"
      },
      "source": [
        "## Dataset creation for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSD6F1JLsDp0"
      },
      "outputs": [],
      "source": [
        "class CNN_Dataset(data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        super().__init__()\n",
        "        self.generate_dataset(X, Y)\n",
        "\n",
        "    def generate_dataset(self, X, Y):\n",
        "        self.data = X\n",
        "        self.size = len(self.data)\n",
        "        labels = []\n",
        "        for index in range(len(Y)):\n",
        "            label = []\n",
        "            label.extend(Y[index][0])\n",
        "            matrix_upper_values = []\n",
        "            for row in range(Y[index][1].shape[0]):\n",
        "                matrix_upper_values.extend(Y[index][1][row][row:])\n",
        "            label.extend(matrix_upper_values)\n",
        "            label = np.array(label)\n",
        "            labels.append(label)\n",
        "        self.label = torch.from_numpy(np.array(labels)).type(torch.FloatTensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_point = self.data[index]\n",
        "        data_label = self.label[index]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhWiIem4sDiU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "d63f4fdd-4050-49b7-a104-dd96a0193e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-952e3c22cbaf>:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  label = np.array(label)\n",
            "<ipython-input-5-952e3c22cbaf>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  label = np.array(label)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a4f2ffe7a22b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX_Index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_N\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_N\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Z_N[n][0][index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mY_Index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_N\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdataset_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mCNNs_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-952e3c22cbaf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-952e3c22cbaf>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ],
      "source": [
        "CNNs_datasets = []\n",
        "for index in range(T):\n",
        "    X_Index = []\n",
        "    Y_Index = []\n",
        "    for n in range(N):\n",
        "        X_Index.append(torch.cat((Z_N[n][0][index], Z_N[n][0][index+1]),0)) #Z_N[n][0][index]\n",
        "        Y_Index.append(Z_N[n][1][index])\n",
        "    dataset_index = CNN_Dataset(X_Index, Y_Index)\n",
        "    CNNs_datasets.append(dataset_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBOogrcCZfbR"
      },
      "outputs": [],
      "source": [
        "# # TESTING\n",
        "# dataset = CNNs_datasets[1]\n",
        "\n",
        "# print(\"Size of dataset:\", len(dataset))\n",
        "# print(\"Dataset : \", [dataset[i] for i in range(len(dataset))])\n",
        "# print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s_SXIZrY7oE"
      },
      "outputs": [],
      "source": [
        "# # TESTING\n",
        "# data_loader = data.DataLoader(dataset, batch_size=1, shuffle=False, drop_last=True)\n",
        "\n",
        "# for batch in data_loader:\n",
        "#     data_inputs, data_labels = next(iter(data_loader))\n",
        "#     print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "#     print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yq5HfZLfxMwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s0-6u2tZp6Z"
      },
      "source": [
        "## Convolutional Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdewTR70sp7G"
      },
      "source": [
        "### CNN Model Architecture Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw5NH1j6UZa9"
      },
      "outputs": [],
      "source": [
        "class Affine_layer(nn.Module):\n",
        "    def __init__(self, input_size: int):\n",
        "        super(Affine_layer, self).__init__()\n",
        "        # initiating the weights and biases\n",
        "        self.weights = nn.Parameter(torch.rand(input_size), requires_grad=True)\n",
        "        self.bias = nn.Parameter(torch.rand(input_size), requires_grad=True)\n",
        "\n",
        "    def forward(self, input_data: torch.tensor):\n",
        "        # simple elementwise multiplication and addition\n",
        "        return ((self.weights * input_data) + self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7s6bs1iB7m6"
      },
      "outputs": [],
      "source": [
        "class Exp_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Exp_layer, self).__init__()\n",
        "\n",
        "    def forward(self, input_data: torch.tensor):\n",
        "        inp = input_data[0] # 1 x d(d+1)/2\n",
        "        inp = inp[d:]\n",
        "        inp = inp.to(device)\n",
        "        temp = torch.zeros(d,d)\n",
        "        temp = temp.to(device)\n",
        "\n",
        "        indices = torch.triu_indices(d, d)\n",
        "        indices.to(device)\n",
        "\n",
        "        temp[indices[0], indices[1]] = inp\n",
        "        matrix = torch.linalg.matrix_exp(temp)\n",
        "\n",
        "        result = input_data\n",
        "        result[0][d:] = matrix[indices[0], indices[1]]\n",
        "\n",
        "        return (result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBAMzIfIw10j"
      },
      "outputs": [],
      "source": [
        "class MainNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Create the network based on the specified hidden layers\n",
        "        layers = []\n",
        "\n",
        "        layers += [nn.Linear(input_size,out_features=input_size*1000)] # Fully Connected layer\n",
        "\n",
        "        # layers += [nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, padding='same', padding_mode='replicate')]\n",
        "        layers += [nn.ReLU()]\n",
        "\n",
        "        layers += [nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, padding='same', padding_mode='replicate')]\n",
        "        layers += [nn.ReLU()]\n",
        "\n",
        "        # layers += [nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, padding='same', padding_mode='replicate')]\n",
        "        # layers += [nn.ReLU()]\n",
        "\n",
        "        layers += [nn.Linear(in_features=input_size*1000, out_features= (d)+(d*(d+1)//2))] # Fully Connected layer\n",
        "\n",
        "        layers += [Exp_layer()]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        result = self.layers(input_data)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvUcysx8uCPe"
      },
      "outputs": [],
      "source": [
        "# # TESTING\n",
        "# # Printing model architecture\n",
        "\n",
        "# MainNetwork_Model = MainNetwork(d*2)\n",
        "# print(\"==== Hyper Network Details ====\\n\",MainNetwork_Model,\"\\n\")\n",
        "\n",
        "# for name, param in MainNetwork_Model.named_parameters():\n",
        "#     print(f\"Parameter {name}, shape {param.shape}\")\n",
        "\n",
        "# num_parameters = sum(p.numel() for p in MainNetwork_Model.parameters())\n",
        "# print(\"\\n Number of parameters = \", num_parameters, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztPRXf1zduCC"
      },
      "source": [
        "### Model Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLDMsgyMR8Sf"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        preds = predictions[0] # 1 x d(d+1)/2\n",
        "        mu_pred = preds[:d]\n",
        "        cov_pred = preds[d:]\n",
        "        cov_pred = cov_pred.to(device)\n",
        "        temp = torch.zeros(d,d)\n",
        "        temp = temp.to(device)\n",
        "        indices = torch.triu_indices(d, d)\n",
        "        indices.to(device)\n",
        "        temp[indices[0], indices[1]] = cov_pred\n",
        "        cov_pred = temp\n",
        "\n",
        "        trgt = targets[0] # 1 x d(d+1)/2\n",
        "        mu_trgt = trgt[:d]\n",
        "        cov_trgt = trgt[d:]\n",
        "        cov_trgt = cov_trgt.to(device)\n",
        "        temp = torch.zeros(d,d)\n",
        "        temp = temp.to(device)\n",
        "        indices = torch.triu_indices(d, d)\n",
        "        indices.to(device)\n",
        "        temp[indices[0], indices[1]] = cov_trgt\n",
        "        cov_trgt = temp\n",
        "\n",
        "        loss = 0.0\n",
        "        # Mean Component\n",
        "        loss += torch.mean(torch.pow(mu_pred-mu_trgt,2))\n",
        "        # Covariant Component\n",
        "        A = torch.matmul(torch.linalg.pinv(cov_pred), cov_trgt)\n",
        "        A_eigen = torch.linalg.eig(A).eigenvalues\n",
        "        A_eigen = torch.real(A_eigen)\n",
        "        A_eigen = torch.log(A_eigen)**2\n",
        "        A_eigen = torch.mean(A_eigen)\n",
        "        loss += A_eigen/2\n",
        "\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import MSELoss\n",
        "A = torch.eye(2)\n",
        "A_eigen = torch.linalg.eig(A).eigenvalues\n",
        "A_eigen = torch.real(A_eigen)\n",
        "A_eigen = torch.log(A_eigen)**2\n",
        "A_eigen = torch.mean(A_eigen)\n",
        "A_eigen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1NwtMdpzjbd",
        "outputId": "30187aca-fb6e-43c3-d84d-f04d11f1fe3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP2wf90jsj0c"
      },
      "outputs": [],
      "source": [
        "def CNN_train_model_with_logger(model, optimizer, data_loader, loss_module, model_index=0, num_epochs=100):\n",
        "    # Create TensorBoard logger\n",
        "    logging_dir='logger/CNN_'+str(model_index)\n",
        "    writer = SummaryWriter(logging_dir)\n",
        "    model_plotted = False\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0.0\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "            # For the very first batch, we visualize the computation graph in TensorBoard\n",
        "            if not model_plotted:\n",
        "                writer.add_graph(model, data_inputs)\n",
        "                model_plotted = True\n",
        "\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad()\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            ## Step 6: Take the running average of the loss\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Add average loss to TensorBoard\n",
        "        epoch_loss /= len(data_loader)\n",
        "        writer.add_scalar('training_loss',\n",
        "                          epoch_loss,\n",
        "                          global_step = epoch + 1)\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC7IqUKDVmGQ"
      },
      "outputs": [],
      "source": [
        "def CNN_train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad()\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snCLtkpB3Cvl"
      },
      "outputs": [],
      "source": [
        "def CNN_eval_model(model, data_loader, loss_module, model_index=0):\n",
        "    # Create TensorBoard logger\n",
        "    logging_dir='logger/CNN_'+str(model_index)\n",
        "    writer = SummaryWriter(logging_dir)\n",
        "    model_plotted = False\n",
        "\n",
        "    # Set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    data_index = 0\n",
        "    num_preds = 0\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "            losses.append(loss)\n",
        "\n",
        "            num_preds += data_labels.shape[0]\n",
        "            data_index += 1\n",
        "            writer.add_scalar('eval_loss', loss, global_step = data_index)\n",
        "\n",
        "    writer.close()\n",
        "    Average_loss = sum(losses) / num_preds\n",
        "    print(\"---- EVAL RESULTS ----\\n\",\"Average loss : \", Average_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzeHhtItKPrz"
      },
      "outputs": [],
      "source": [
        "def CNN_predict(model, data):\n",
        "    model.eval() # Set model to eval mode\n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        data = data.to(device)\n",
        "        preds = model(data)\n",
        "        preds = preds.squeeze(dim=1)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj9fTBFneBbe"
      },
      "source": [
        "## Creating And Training The CNN Instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4kwJDwhe1g8"
      },
      "outputs": [],
      "source": [
        "def DataLoader_for_Model(model_index,  test_ratio=0.2, batch_size=1):\n",
        "    full_dataset = CNNs_datasets[model_index]\n",
        "    test_size = int(test_ratio * len(full_dataset))\n",
        "    train_size = len(full_dataset) - test_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    train_data_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    test_data_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "    return train_data_loader, test_data_loader\n",
        "\n",
        "def Model_Maker(train_data_loader, test_data_loader, model_index, with_logger=False, with_eval=False):\n",
        "    model = MainNetwork(2*d)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_module = nn.MSELoss()\n",
        "    if with_logger:\n",
        "        CNN_train_model_with_logger(model, optimizer, train_data_loader, loss_module, model_index)\n",
        "    else:\n",
        "        CNN_train_model(model, optimizer, train_data_loader, loss_module)\n",
        "    if with_eval:\n",
        "        CNN_eval_model(model, test_data_loader, loss_module, model_index)\n",
        "    return model\n",
        "\n",
        "def Model_Param_Extractor(model):\n",
        "    paramete_vectors_sizes = []\n",
        "    paramete_vectors_sizes_flatten = []\n",
        "    paramete_vectors_values = []\n",
        "\n",
        "    for param_tensor in model.state_dict():\n",
        "        paramete_vectors_sizes.append(model.state_dict()[param_tensor].shape)\n",
        "        paramete_vectors_sizes_flatten.append(torch.flatten(model.state_dict()[param_tensor]).shape[0])\n",
        "        paramete_vectors_values += (torch.flatten(model.state_dict()[param_tensor]).tolist())\n",
        "\n",
        "    model_params_and_info = [paramete_vectors_sizes, paramete_vectors_sizes_flatten, paramete_vectors_values]\n",
        "    return model_params_and_info\n",
        "\n",
        "def MainModel_Saver(model, model_index):\n",
        "    if not os.path.exists(\"CNN_Models/\"):\n",
        "        os.mkdir(\"CNN_Models/\")\n",
        "    PATH = \"./CNN_Models/CNN\"+str(model_index)+\".pt\"\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    return\n",
        "\n",
        "def MainModel_Loader(PATH):\n",
        "    model = torch.load(PATH)\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "949a8d5f42b54bd8b49e9b0059924810",
            "f7eabf29f1e742088d68a4f6c91a77c6",
            "25335ed8dd054ea3877dc546dddabdf5",
            "1c9d30afd93e42e2be5c4d4213c0b21d",
            "c3411d615d2347bd90f1b42bf160bac6",
            "e7a7b768d7de42fcb1be543e37771521",
            "e79bf3afffc84f6199990c6e9334fed8",
            "86a835b8a5614c6ba8206c217235b83b",
            "82db98c3ff964f0eab8b452df1bd9436",
            "3c64ba16c4b04779b66c6797789d03e0",
            "1ddccb91469c49518fe9f84802cf6f88"
          ]
        },
        "id": "8o_8-4ETePM4",
        "outputId": "cf158487-e7f1-4d80-aaf1-eb22ccb09c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== \n",
            " Start working on CNN 1 out of  1\n",
            "---- Creating Datasets ----\n",
            "---- Creating model instance and training ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "949a8d5f42b54bd8b49e9b0059924810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- EVAL RESULTS ----\n",
            " Average loss :  tensor(1.3644e-06)\n",
            "---- Extracting model parameters ----\n",
            "---- Saving model state ----\n",
            "---- Clearing GPU's cache memory ----\n",
            "Done with CNN 0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "number_of_CNNs = T\n",
        "CNNs_parameters = []\n",
        "\n",
        "for index in range(number_of_CNNs):\n",
        "    print(\"=\"*20, \"\\n\", \"Start working on CNN\", index + 1,  \"out of \", number_of_CNNs)\n",
        "    print(\"---- Creating Datasets ----\")\n",
        "    CNN_train_data, CNN_test_data = DataLoader_for_Model(index)\n",
        "    print(\"---- Creating model instance and training ----\")\n",
        "    CNN_Model = Model_Maker(CNN_train_data, CNN_test_data, index, with_logger=True, with_eval=True)\n",
        "    print(\"---- Extracting model parameters ----\")\n",
        "    CNN_Params_and_Info = Model_Param_Extractor(CNN_Model)\n",
        "    CNNs_parameters.append(CNN_Params_and_Info)\n",
        "    print(\"---- Saving model state ----\")\n",
        "    MainModel_Saver(CNN_Model, index)\n",
        "    print(\"---- Clearing GPU's cache memory ----\")\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Done with CNN\", index, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGY5oA2oHiM8"
      },
      "outputs": [],
      "source": [
        "!kill $(ps -e | grep 'tensorboard' | awk '{print $1}')\n",
        "%tensorboard --logdir /content/logger/CNN_2/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill $(ps -e | grep 'tensorboard' | awk '{print $1}')\n",
        "%tensorboard --logdir /content/logger/CNN_4/"
      ],
      "metadata": {
        "id": "vyHvwISx6HD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nKkaQSlnEqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Results"
      ],
      "metadata": {
        "id": "tgB7W-LknFQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "torch.save(CNNs_parameters, 'CNNs_parameters.pt')\n",
        "shutil.make_archive('CNN_Models', 'zip', './CNN_Models/')\n",
        "shutil.make_archive('CNN_Logs', 'zip', './logger/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SeEoNq62nCYj",
        "outputId": "62a9fce6-8f8f-46aa-8f52-2639aecd365c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_adfa50e6-7002-4114-9d53-411249ac5ef7\", \"CNNs_parameters.pt\", 90687)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf0b491a-ecfa-4d8e-9c30-1d621f4c8ea9\", \"CNN_Models.zip\", 37282)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e91b7843-5dc6-4477-9609-4a2e2405c1a8\", \"CNN_Logs.zip\", 8096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('CNNs_parameters.pt')\n",
        "files.download('CNN_Models.zip')\n",
        "files.download('CNN_Logs.zip')"
      ],
      "metadata": {
        "id": "mIQQolUaq4is"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}