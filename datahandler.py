# -*- coding: utf-8 -*-
"""DataHandler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bvYO21NVaR-d9-2eJkZqZ-ZDnsz9KLm5

# Environment Setup
"""

! pip install ydata-profiling

# Commented out IPython magic to ensure Python compatibility.
## Standard libraries
import os
import time
import json
import math
import numpy as np
import scipy
from scipy.linalg import fractional_matrix_power as frac_mat_pow

## Imports for plotting
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set()

## Progress bar
from tqdm.notebook import tqdm

## PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
# %load_ext tensorboard

# Function for setting the seed
def set_seed(seed):
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available(): # GPU operation have separate seed
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
set_seed(42)

# Additionally, some operations on a GPU are implemented stochastic for efficiency
# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# Fetching the device that will be used throughout this notebook
device = torch.device("cpu") if not torch.cuda.is_available() else torch.device("cuda:0")
print("Using device", device)

"""# Algorithm 3 (X Constructor)

Require:
- Number of training samples $N ∈ N_+$
- time-horizon $T ∈ N_+$
- dynamics $μ$
- $σ$
- $ς$
- “noise” parameter $0 ≤ λ$
- memory $1 ≤ w ≤ 0$

Given parameters :
1. $N=100$,
2. $T=20$,
3. $d=16$,
4. $\mu(x)=x$,
5. $\sigma = I_d$,
6. $\varsigma(x)= 1,|\sin(\|x\|)+0.0001|$
7. $\lambda=0,1$
8. $w=0.5$
"""

N = 1000000 # Number of paths/datapoints (time & space together)
T = 100 # the Time-Horizon
d = 1 # the dimension of the data
Sigma = torch.eye(d) # diffusion parameter sigma (σ)
Lambda = 0 # the randomness parameter (λ) for indices 0 to T
memory = 0

def mu(x):
    return (0.01-x)/2

def varsigma(x):
    return torch.ones([x.shape[0], 1, 1])*0.001 #torch.abs(torch.sin(torch.from_numpy(np.array(x)).type(torch.FloatTensor)) + 0.0001)

X = [] # change to torch tensor !!!!
Drift = []
Diffusion = []
for n in range(N):  # REMOVE THIS !!!!
    x_n = []
    Drift_n = []
    Diffusion_n = []
    for t in range(T+1):
        if t == 0:
            x_n.append(torch.zeros(d, d)) # X[-1]
            Drift_n.append(torch.zeros(d))
            Diffusion_n.append(torch.zeros(d, d))
            x_n.append(torch.zeros(d, d)) # X[0]
            Drift_n.append(torch.zeros(d))
            Diffusion_n.append(torch.zeros(d, d))
        else:
            Z = torch.randn(d)
            B = torch.bernoulli(torch.tensor([0.5]))
            drift_n_t = memory * mu(x_n[-2]) + (1-memory) * mu(x_n[-1]) # Drift[t] but in place [t+1]
            diffusion_n_t = ((varsigma(x_n[-1]) * Sigma) + ((B * Lambda) * torch.eye(d))) * Z # Diffusion[t] but in place [t+1]
            x_n_t1 = torch.from_numpy(np.array(x_n[-1] + drift_n_t + diffusion_n_t)).type(torch.FloatTensor) # X[t+1]
            x_n.append(x_n_t1)
            Drift_n.append(drift_n_t)
            Diffusion_n.append(diffusion_n_t)
    X.append(x_n)
    Drift.append(Drift_n)
    Diffusion.append(Diffusion_n)

X = []
Drift = []
Diffusion = []

for t in range(T+1):
    if t == 0:
        X.append(torch.zeros(n, d)) # X[-1]
        Drift.append(torch.zeros(n, d))
        Diffusion.append(torch.zeros(n, d))
        X.append(torch.zeros(n, d)) # X[0]
        Drift.append(torch.zeros(n, d))
        Diffusion.append(torch.zeros(n, d))
    else:
        Z = torch.randn(n, d)
        B = torch.bernoulli(torch.tensor([0.5]*n))
        drift_t = memory * mu(X[t-2]) + (1-memory) * mu(X[t-1])     # Drift[t] but in place [t+1]
        eye_reshaped = torch.eye(d).reshape([1,d,d])
        B_reshaped = B.reshape([n, 1])
        diffusion_t = torch.einsum("nij,jk,nk->ni", varsigma(X[t-1]), Sigma, Z) + ((B_reshaped * Lambda) * Z) # Diffusion[t] but in place [t+1]
        x_t1 = X[t-1] + drift_t + diffusion_t  # X[t+1]
        X.append(x_t1)
        Drift.append(drift_t)
        Diffusion.append(diffusion_t)

X_all = torch.stack(X, dim=1)
Drift_all = torch.stack(Drift, dim=1)
Diffusion_all = torch.stack(Diffusion, dim=1)

X = X_all[:, 2:, :]

quantiles = torch.quantile(X, torch.tensor([0.05, 0.5, 0.95]), dim=0)
print(quantiles.shape)
fig = plt.figure(figsize=(16,8))
plt.plot(quantiles[0])
plt.plot(quantiles[1])
plt.plot(quantiles[2])
plt.plot(X[0])



X[0][:10]

X = [[torch.diagonal(t_n, 0) for t_n in n] for n in X]
X[0][:10]

# # # Testing

# for i in range(1, T):
#     print(X[0][i]-X[0][i-1])

# fig = plt.figure(figsize=(16,8))
# plt.plot(X[0])
# plt.show()
print("*"*40)
for i in range(10):
    print("#"*10,i,"#"*10)
    print(X[0][i])
    print("*"*10)
    print(Drift[0][i])
    print("*"*10)
    print(Diffusion[0][i])
    print("\n\n\n\n")

"""# Algorithm 1 (Input-Output Generator)"""

sigma_2 = torch.matrix_power(Sigma,2)
sigma_neg_2 = torch.matrix_power(torch.linalg.pinv(Sigma), 2)
Z_N = []
for n in range(N):
    x_n = X[n]
    drift_n = Drift[n]
    Y_X = []
    for t in range(T):
        x_t = x_n[t+1] # the X was indexed from -1
        drift_t = drift_n[t+1] # Drift_n_t (indexes for drift are one ahead)
        mu_x_t =  x_t + drift_t
        sigma_x_t = torch.mul(
            varsigma(x_t),
            torch.matmul(
                sigma_2,
                torch.from_numpy(frac_mat_pow(
                    torch.matmul(
                        sigma_neg_2,
                        torch.matrix_power(
                            torch.add(
                                torch.mul(Lambda, torch.eye(d)),
                                torch.mul(varsigma(x_t), Sigma))
                            , 2)
                        )
                    , 1/2)).type(torch.FloatTensor)
                )
            )
        Y_X.append([mu_x_t, sigma_x_t])
    Z = [x_n, Y_X]
    Z_N.append(Z)

# # # TESTING
for i in range(4):
    print("#"*5,i,"#"*5)
    print("\tX")
    print(Z_N[0][0][i])
    print("\tY_X, containing mu and sigma")
    print(Z_N[0][1][i][0])
    print(Z_N[0][1][i][1])
    print("\n\n\n\n")


# fig1 = plt.figure(figsize=(16,8))
# plt.title("Z_N[0][0]")
# plt.plot(Z_N[0][0])
# plt.show()


# fig2 = plt.figure(figsize=(16,8))
# plt.title("Z_N[0][1]")
# plt.plot(Z_N[0][1])
# plt.show()

"""## Saving Results"""

from google.colab import files

vars = [N, T, d]
torch.save(vars, 'vars.pt')
torch.save(Z_N, 'Z_N.pt')

files.download('vars.pt')
files.download('Z_N.pt')

!du -hal

"""## Profiling"""

import pandas as pd
from ydata_profiling import ProfileReport


df = pd.read_csv("data/Train_Dataset.csv")
profile = ProfileReport(df, title="Pandas Profiling Report")
profile